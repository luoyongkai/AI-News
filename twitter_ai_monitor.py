import requests
import time
import json
import os
from datetime import datetime, timedelta
from openai import OpenAI


class TwitterAIMonitor:
    """Twitteræ¨æ–‡ç›‘æ§å’ŒAIå¤„ç†å™¨"""
    
    def __init__(self, twitter_api_key: str, llm_url: str, llm_api_key: str, data_dir: str = "data"):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        :param twitter_api_key: TwitterAPI.io API Key
        :param llm_url: å¤§æ¨¡å‹æ¥å£URL
        :param llm_api_key: å¤§æ¨¡å‹API Key
        :param data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        """
        self.twitter_api_key = twitter_api_key
        self.llm_client = OpenAI(
            api_key=llm_api_key,
            base_url=llm_url,
        )
        self.data_dir = data_dir
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
    
    def get_ai_response(self, prompt: str) -> str:
        """
        è°ƒç”¨AIæ¨¡å‹è·å–å“åº”
        
        :param prompt: è¾“å…¥æç¤ºè¯
        :return: AIå“åº”å†…å®¹
        """
        try:
            completion = self.llm_client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt},
                ]
            )
            return completion.choices[0].message.content
        except Exception as e:
            print(f"AIè°ƒç”¨å‡ºé”™: {e}")
            return "AIå¤„ç†å¤±è´¥"
    
    def process_tweet_with_ai(self, tweet_text: str) -> dict:
        """
        ä½¿ç”¨AIå¤„ç†æ¨æ–‡ï¼šç¿»è¯‘ã€è§£è¯»ã€ç”Ÿæˆæ ‡é¢˜
        
        :param tweet_text: æ¨æ–‡å†…å®¹
        :return: åŒ…å«AIå¤„ç†ç»“æœçš„å­—å…¸
        """
        # ç¿»è¯‘æ¨æ–‡
        translate_prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡æ¨æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒåŸæ„å’Œè¯­æ°”ï¼š

æ¨æ–‡å†…å®¹ï¼š{tweet_text}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""
        
        translation = self.get_ai_response(translate_prompt)
        
        # è§£è¯»æ¨æ–‡
        analysis_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ¨æ–‡è¿›è¡Œæ·±åº¦è§£è¯»åˆ†æï¼ŒåŒ…æ‹¬å…¶å«ä¹‰ã€èƒŒæ™¯ã€å¯èƒ½çš„å½±å“ç­‰,å…¨æ–‡å†…å®¹åœ¨160å­—å·¦å³ï¼š

æ¨æ–‡å†…å®¹ï¼š{tweet_text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. æ¨æ–‡çš„ä¸»è¦ä¿¡æ¯å’Œè§‚ç‚¹
2. å¯èƒ½çš„èƒŒæ™¯å’ŒåŸå› 
3. å¯¹ç›¸å…³é¢†åŸŸçš„å½±å“
4. å…¶ä»–å€¼å¾—å…³æ³¨çš„è¦ç‚¹

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå†…å®¹è¦æœ‰æ·±åº¦å’Œè§è§£ã€‚"""
        
        analysis = self.get_ai_response(analysis_prompt)
        
        # ç”Ÿæˆæ ‡é¢˜
        title_prompt = f"""è¯·ä¸ºä»¥ä¸‹æ¨æ–‡ç”Ÿæˆä¸€ä¸ªç®€æ´æœ‰åŠ›çš„ä¸­æ–‡æ ‡é¢˜ï¼Œè¦æ±‚ï¼š
1. æ§åˆ¶åœ¨15-25ä¸ªå­—ä»¥å†…
2. èƒ½å¤Ÿå‡†ç¡®æ¦‚æ‹¬æ¨æ–‡çš„æ ¸å¿ƒå†…å®¹
3. å…·æœ‰å¸å¼•åŠ›å’Œæ–°é—»æ€§

æ¨æ–‡å†…å®¹ï¼š{tweet_text}

è¯·åªè¿”å›æ ‡é¢˜ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""
        
        title = self.get_ai_response(title_prompt)
        
        return {
            'title': title.strip(),
            'translation': translation.strip(),
            'analysis': analysis.strip()
        }
    
    def get_tweets_from_account(self, account: str, since_time: datetime, until_time: datetime, exclude_replies: bool = False) -> list:
        """
        è·å–æŒ‡å®šè´¦å·åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ¨æ–‡
        
        :param account: Twitterè´¦å·
        :param since_time: å¼€å§‹æ—¶é—´
        :param until_time: ç»“æŸæ—¶é—´
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        :return: æ¨æ–‡åˆ—è¡¨
        """
        since_str = since_time.strftime("%Y-%m-%dT%H:%M:%SZ")
        until_str = until_time.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ’é™¤å›å¤
        if exclude_replies:
            query = f"from:{account} -is:reply since:{since_str} until:{until_str} include:nativeretweets"
        else:
            query = f"from:{account} since:{since_str} until:{until_str} include:nativeretweets"
            
        url = "https://api.twitterapi.io/twitter/tweet/advanced_search"
        params = {"query": query, "queryType": "Latest"}
        headers = {"X-API-Key": self.twitter_api_key}
        
        all_tweets = []
        next_cursor = None
        
        while True:
            if next_cursor:
                params["cursor"] = next_cursor
            
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                tweets = data.get("tweets", [])
                
                if tweets:
                    for t in tweets:
                        t['author'] = account  # æ·»åŠ ä½œè€…ä¿¡æ¯
                    all_tweets.extend(tweets)
                
                if data.get("has_next_page", False) and data.get("next_cursor", "") != "":
                    next_cursor = data.get("next_cursor")
                    continue
                else:
                    break
            else:
                print(f"è·å–æ¨æ–‡å‡ºé”™: {response.status_code} - {response.text}")
                break
        
        return all_tweets
    
    def save_tweet_data(self, tweet_data: dict):
        """
        ä¿å­˜æ¨æ–‡æ•°æ®åˆ°JSONæ–‡ä»¶ï¼ŒæŒ‰å¤©å­˜å‚¨
        
        :param tweet_data: æ¨æ–‡æ•°æ®
        """
        today = datetime.now().strftime("%Y-%m-%d")
        file_path = os.path.join(self.data_dir, f"tweets_{today}.json")
        
        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = []
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except json.JSONDecodeError:
                existing_data = []
        
        # æ£€æŸ¥æ˜¯å¦é‡å¤ - æ ¹æ®æ¨æ–‡IDå»é‡
        tweet_id = tweet_data.get('id')
        existing_ids = {item.get('id') for item in existing_data if item.get('id')}
        
        if tweet_id not in existing_ids:
            # æ·»åŠ æ–°æ•°æ®ï¼ˆä»…å½“IDä¸é‡å¤æ—¶ï¼‰
            existing_data.append(tweet_data)
            print(f"ä¿å­˜æ–°æ¨æ–‡: {tweet_id} - {tweet_data.get('author', 'Unknown')}")
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
        else:
            print(f"è·³è¿‡é‡å¤æ¨æ–‡: {tweet_id} - {tweet_data.get('author', 'Unknown')}")
    
    def load_tweets_by_date(self, date_str: str = None) -> list:
        """
        æ ¹æ®æ—¥æœŸåŠ è½½æ¨æ–‡æ•°æ®
        
        :param date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        :return: æ¨æ–‡æ•°æ®åˆ—è¡¨
        """
        if date_str is None:
            date_str = datetime.now().strftime("%Y-%m-%d")
        
        file_path = os.path.join(self.data_dir, f"tweets_{date_str}.json")
        
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except json.JSONDecodeError:
                return []
        return []
    
    def get_all_tweets(self) -> list:
        """
        è·å–æ‰€æœ‰å­˜å‚¨çš„æ¨æ–‡æ•°æ®
        
        :return: æ‰€æœ‰æ¨æ–‡æ•°æ®åˆ—è¡¨
        """
        all_tweets = []
        
        # éå†æ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
        if os.path.exists(self.data_dir):
            for filename in os.listdir(self.data_dir):
                if filename.startswith("tweets_") and filename.endswith(".json"):
                    file_path = os.path.join(self.data_dir, filename)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            tweets = json.load(f)
                            all_tweets.extend(tweets)
                    except json.JSONDecodeError:
                        continue
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        all_tweets.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        return all_tweets
    
    def monitor_and_process(self, target_accounts: list, check_interval: int = 300, hours: int = 1, exclude_replies: bool = False):
        """
        ç›‘æ§Twitterè´¦å·å¹¶ä½¿ç”¨AIå¤„ç†æ–°æ¨æ–‡
        
        :param target_accounts: è¦ç›‘æ§çš„è´¦å·åˆ—è¡¨
        :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        :param hours: åˆå§‹å›æº¯æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        """
        last_checked_time = datetime.utcnow() - timedelta(hours=hours)
        
        def check_and_process_tweets():
            nonlocal last_checked_time
            until_time = datetime.utcnow()
            since_time = last_checked_time
            
            all_tweets = []
            
            for account in target_accounts:
                tweets = self.get_tweets_from_account(account, since_time, until_time, exclude_replies)
                all_tweets.extend(tweets)
                
                # æ·»åŠ 5ç§’å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if account != target_accounts[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªè´¦å·ï¼Œæ·»åŠ å»¶è¿Ÿ
                    print("ç­‰å¾…5ç§’ï¼Œé¿å…APIè¯·æ±‚é™åˆ¶...")
                    time.sleep(5)
            
            if all_tweets:
                print(f"å‘ç° {len(all_tweets)} æ¡æ–°æ¨æ–‡ï¼Œå¼€å§‹AIå¤„ç†...\n")
                
                for idx, tweet in enumerate(all_tweets, start=1):
                    print(f"{'='*60}")
                    print(f"å¤„ç†æ¨æ–‡ {idx}/{len(all_tweets)}")
                    print(f"{'='*60}")
                    
                    # åŸºæœ¬ä¿¡æ¯
                    tweet_id = tweet.get('id') or tweet.get('id_str')
                    tweet_url = f"https://twitter.com/{tweet['author']}/status/{tweet_id}"
                    original_text = tweet.get('text', '')
                    
                    print(f"ä½œè€…ï¼š{tweet['author']}")
                    print(f"å‘å¸ƒæ—¶é—´ï¼š{tweet.get('createdAt')}")
                    print(f"åŸæ–‡ï¼š{original_text}")
                    print(f"é“¾æ¥ï¼š{tweet_url}")
                    print()
                    
                    # AIå¤„ç†
                    print("AIå¤„ç†ä¸­...")
                    ai_result = self.process_tweet_with_ai(original_text)
                    
                    print(f"AIæ ‡é¢˜ï¼š{ai_result['title']}")
                    print(f"AIç¿»è¯‘ï¼š{ai_result['translation']}")
                    print(f"AIè§£è¯»ï¼š{ai_result['analysis']}")
                    print(f"{'='*60}\n")
                    
                    # ä¿å­˜æ•°æ®åˆ°JSON
                    tweet_data = {
                        'id': tweet_id,
                        'author': tweet['author'],
                        'created_at': tweet.get('createdAt'),
                        'original_text': original_text,
                        'tweet_url': tweet_url,
                        'ai_title': ai_result['title'],
                        'ai_translation': ai_result['translation'],
                        'ai_analysis': ai_result['analysis'],
                        'timestamp': datetime.utcnow().isoformat(),
                        'processed_date': datetime.now().strftime("%Y-%m-%d")
                    }
                    self.save_tweet_data(tweet_data)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    time.sleep(2)
            else:
                print(f"{datetime.utcnow()} - æ²¡æœ‰å‘ç°æ–°æ¨æ–‡ã€‚")
            
            last_checked_time = until_time
        
        print(f"å¼€å§‹ç›‘æ§è´¦å·: {', '.join(target_accounts)}")
        print(f"æ£€æŸ¥é—´éš”: {check_interval} ç§’")
        print(f"AIå¤„ç†åŠŸèƒ½å·²å¯ç”¨\n")
        
        try:
            while True:
                check_and_process_tweets()
                print(f"ç­‰å¾… {check_interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                time.sleep(check_interval)
        except KeyboardInterrupt:
            print("ç›‘æ§å·²åœæ­¢ã€‚")
    
    def monitor_and_process_with_status(self, target_accounts: list, check_interval: int = 300, hours: int = 1, status_dict: dict = None, exclude_replies: bool = False):
        """
        å¸¦çŠ¶æ€æ›´æ–°çš„ç›‘æ§åŠŸèƒ½
        
        :param target_accounts: è¦ç›‘æ§çš„è´¦å·åˆ—è¡¨
        :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        :param hours: åˆå§‹å›æº¯æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        :param status_dict: çŠ¶æ€å­—å…¸ï¼Œç”¨äºæ›´æ–°å‰ç«¯æ˜¾ç¤º
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        """
        last_checked_time = datetime.utcnow() - timedelta(hours=hours)
        
        def update_status(status, account="", result=""):
            if status_dict:
                status_dict["current_status"] = status
                status_dict["current_account"] = account
                status_dict["last_update"] = datetime.now().isoformat()
                if result:
                    status_dict["last_result"] = result
                # è®¡ç®—ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´
                next_time = datetime.now() + timedelta(seconds=check_interval)
                status_dict["next_check_time"] = next_time.isoformat()
        
        def check_and_process_tweets():
            nonlocal last_checked_time
            until_time = datetime.utcnow()
            since_time = last_checked_time
            
            all_tweets = []
            
            try:
                # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹æŠ“å–
                update_status("ğŸ” æ‰«æä¸­", f"{', '.join(target_accounts)}")
                
                for account in target_accounts:
                    try:
                        update_status(f"ğŸ“¡ æ­£åœ¨æŠ“å– @{account} çš„æ¨æ–‡...")
                        tweets = self.get_tweets_from_account(account, since_time, until_time, exclude_replies)
                        all_tweets.extend(tweets)
                        print(f"âœ… æˆåŠŸè·å– @{account} çš„ {len(tweets)} æ¡æ¨æ–‡")
                        
                        # æ·»åŠ 5ç§’å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                        if account != target_accounts[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªè´¦å·ï¼Œæ·»åŠ å»¶è¿Ÿ
                            print("ç­‰å¾…5ç§’ï¼Œé¿å…APIè¯·æ±‚é™åˆ¶...")
                            time.sleep(5)
                            
                    except Exception as e:
                        print(f"âŒ è·å– @{account} æ¨æ–‡å¤±è´¥: {str(e)}")
                        update_status(f"âš ï¸ @{account} æ•°æ®è·å–å¼‚å¸¸", result=f"é”™è¯¯: {str(e)}")
                        continue
            except Exception as e:
                print(f"âŒ æ¨æ–‡æ‰«æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                update_status(f"âš ï¸ æ‰«æè¿‡ç¨‹å¼‚å¸¸", result=f"é”™è¯¯: {str(e)}")
                return
            
            if all_tweets:
                update_status(f"ğŸ¤– å‘ç° {len(all_tweets)} æ¡æ–°æ¨æ–‡ï¼ŒAIåˆ†æä¸­...", result=f"æ‰¾åˆ° {len(all_tweets)} æ¡æ–°æ¨æ–‡")
                
                for idx, tweet in enumerate(all_tweets, start=1):
                    # åŸºæœ¬ä¿¡æ¯
                    tweet_id = tweet.get('id') or tweet.get('id_str')
                    tweet_url = f"https://twitter.com/{tweet['author']}/status/{tweet_id}"
                    original_text = tweet.get('text', '')
                    
                    # æ›´æ–°çŠ¶æ€ï¼šAIå¤„ç†ä¸­
                    update_status(f"ğŸ§  AIå¤„ç†ä¸­... ({idx}/{len(all_tweets)})", f"@{tweet['author']}")
                    
                    # AIå¤„ç†
                    try:
                        ai_result = self.process_tweet_with_ai(original_text)
                    except Exception as e:
                        print(f"âŒ AIå¤„ç†æ¨æ–‡å¤±è´¥: {str(e)}")
                        ai_result = {
                            'title': f"å¤„ç†å¤±è´¥: {str(e)[:50]}",
                            'translation': original_text,
                            'analysis': f"AIå¤„ç†å¤±è´¥: {str(e)}"
                        }
                    
                    # ä¿å­˜æ•°æ®åˆ°JSON
                    tweet_data = {
                        'id': tweet_id,
                        'author': tweet['author'],
                        'created_at': tweet.get('createdAt'),
                        'original_text': original_text,
                        'tweet_url': tweet_url,
                        'ai_title': ai_result['title'],
                        'ai_translation': ai_result['translation'],
                        'ai_analysis': ai_result['analysis'],
                        'timestamp': datetime.utcnow().isoformat(),
                        'processed_date': datetime.now().strftime("%Y-%m-%d")
                    }
                    self.save_tweet_data(tweet_data)
                    
                    # æ›´æ–°å¤„ç†è®¡æ•°
                    if status_dict:
                        status_dict["processed_tweets"] = status_dict.get("processed_tweets", 0) + 1
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    time.sleep(2)
                
                update_status("âœ… å¤„ç†å®Œæˆ", result=f"æˆåŠŸå¤„ç† {len(all_tweets)} æ¡æ¨æ–‡")
            else:
                update_status("â­ æ™ºèƒ½å¾…æœºä¸­", result="æœªå‘ç°æ–°æ¨æ–‡ï¼Œç»§ç»­ç›‘æ§ä¸­...")
            
            last_checked_time = until_time
        
        update_status("ğŸš€ Neural Network å·²å¯åŠ¨", f"ç›‘æ§ {len(target_accounts)} ä¸ªè´¦å·")
        print(f"ğŸš€ ç›‘æ§å¯åŠ¨æˆåŠŸï¼Œç›®æ ‡è´¦å·: {target_accounts}")
        
        try:
            while status_dict and status_dict.get("running", False):
                print(f"ğŸ”„ å¼€å§‹æ–°ä¸€è½®æ£€æŸ¥å¾ªç¯...")
                check_and_process_tweets()
                
                # å€’è®¡æ—¶ç­‰å¾…
                for remaining in range(check_interval, 0, -10):
                    if not status_dict.get("running", False):
                        print("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºç›‘æ§")
                        break
                    update_status(f"â±ï¸ ä¸‹æ¬¡æ‰«æå€’è®¡æ—¶ {remaining}s", result=status_dict.get("last_result", ""))
                    time.sleep(10)
                    
        except KeyboardInterrupt:
            print("ğŸ›‘ ç›‘æ§è¢«ä¸­æ–­")
            update_status("ğŸ›‘ Neural Network å·²åœæ­¢")
        except Exception as e:
            print(f"âŒ ç›‘æ§è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            update_status("âŒ ç›‘æ§å¼‚å¸¸åœæ­¢", result=f"é”™è¯¯: {str(e)}")
            if status_dict:
                status_dict["running"] = False


# ä¸»ç¨‹åº
if __name__ == "__main__":
    # ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    config_file = "config.json"
    
    # é»˜è®¤é…ç½®
    default_config = {
        "TWITTER_API_KEY": "b74c1eefe10044a582d9a3c6b82c4ee5",
        "LLM_URL": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "LLM_API_KEY": "sk-bf2a9bf3ce4d431096b344d8bbe5fbdc",
        "TARGET_ACCOUNTS": ["OpenAI"],
        "CHECK_INTERVAL": 300,
        "INITIAL_HOURS": 64,
        "EXCLUDE_REPLIES": False # æ–°å¢é…ç½®é¡¹
    }
    
    # è¯»å–é…ç½®æ–‡ä»¶
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # åˆå¹¶é»˜è®¤é…ç½®
                for key, value in default_config.items():
                    if key not in config:
                        config[key] = value
        except Exception as e:
            print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            config = default_config
    else:
        print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = default_config
    
    # æå–é…ç½®å‚æ•°
    TWITTER_API_KEY = config["TWITTER_API_KEY"]
    LLM_URL = config["LLM_URL"]
    LLM_API_KEY = config["LLM_API_KEY"]
    TARGET_ACCOUNTS = config["TARGET_ACCOUNTS"]
    CHECK_INTERVAL = config["CHECK_INTERVAL"]
    INITIAL_HOURS = config["INITIAL_HOURS"]
    EXCLUDE_REPLIES = config["EXCLUDE_REPLIES"] # ä»é…ç½®åŠ è½½
    
    print(f"å¼€å§‹ç›‘æ§è´¦å·: {', '.join(TARGET_ACCOUNTS)}")
    print(f"æ£€æŸ¥é—´éš”: {CHECK_INTERVAL}ç§’")
    print(f"åˆå§‹å›æº¯: {INITIAL_HOURS}å°æ—¶")
    print(f"æ˜¯å¦æ’é™¤å›å¤: {EXCLUDE_REPLIES}") # æ‰“å°é…ç½®
    
    # åˆ›å»ºç›‘æ§å™¨å¹¶å¼€å§‹ç›‘æ§
    monitor = TwitterAIMonitor(TWITTER_API_KEY, LLM_URL, LLM_API_KEY)
    monitor.monitor_and_process(TARGET_ACCOUNTS, CHECK_INTERVAL, INITIAL_HOURS, EXCLUDE_REPLIES) 